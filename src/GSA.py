# -*- coding: utf-8 -*-
"""model-experiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yrBef9EmQrvPSZe4U1xY-AYMYB0IKl0x
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive')
# %cd /content/gdrive/My Drive/Kaggle

import numpy as np
indiana_pines = np.load('indianpinearray.npy')
ground_truth = np.load('IPgt.npy')

!pip install spectral

import spectral as sp
view = sp.imshow(indiana_pines, (145, 145, 199))

import matplotlib.pyplot as plt
plt.imshow(ground_truth)
print(np.unique(ground_truth))

flattened_image = np.reshape(indiana_pines,(-1,indiana_pines.shape[-1])).astype(np.int16)
flattened_ground = np.reshape(ground_truth,(-1,)).astype(np.int16)

import torch
import torch.optim as optim

def flatten(X):
    if len(X.shape) <= 2:
        X = X
    else:
        X = np.reshape(X,(-1,X.shape[-1]))
    return X

def standard(X):
    from sklearn.preprocessing import StandardScaler
    return StandardScaler().fit_transform(flatten(X))

def unflatten(X,size=145):
    return np.reshape(X,(size,-1,X.shape[-1]))

device = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")
x_tensor = torch.Tensor(flattened_image).to(device)
y_tensor = torch.Tensor(flattened_ground).to(device)
y_idx = y_tensor.nonzero(as_tuple=True)[0].to(device)
y_tensor = y_tensor[y_idx].to(device)
x_tensor = x_tensor[y_idx].to(device)
#np.unique(y_tensor)

torch.cuda.memory_allocated()

class TorchStandardScaler:
  def fit(self, x):
    self.mean = x.mean(1, keepdim=True)
    self.std = x.std(1, unbiased=False, keepdim=True)
  def transform(self, x):
    x -= self.mean
    x /= (self.std + 1e-7)
    return x

scaler=TorchStandardScaler()
scaler.fit(x_tensor)
x_tensor = scaler.transform(x_tensor).to(device)
ones = torch.ones(size=(x_tensor.shape[0],)).to(device)
y_tensor = torch.sub(y_tensor,ones).to(device)
num_bands = x_tensor.shape[1]
x_tensor_slice = [x_tensor[:,i] for i in range(num_bands)]
torch.set_num_threads(2)

def preprocess(x_tensor=x_tensor,y_tensor=y_tensor,num_class=16):
  classes = [x_tensor[(y_tensor == i).nonzero(as_tuple=True)[0],:] for i in range(0,num_class)]
  res = {
      "mean":{
          k:torch.mean(classes[k],dim = 0) for k in range(0,num_class)
      }
  }
  
  res["mean_stack"] = torch.stack(tuple([v for k,v in res["mean"].items()]))
  res["band_mean"] = torch.mean(x_tensor,dim=0).view(1,-1)

  res["band_mean_product"] = torch.mm(torch.t(res["band_mean"]),res["band_mean"])
  
  res["covariance"] = torch.Tensor(np.cov(torch.t(x_tensor).cpu())).to(device)

  res["mean_diffs"] = (res["mean_stack"].unsqueeze(1) - res["mean_stack"])
  
  res["correlation"] = torch.add(res["covariance"],res["band_mean_product"])
  # REMOVE COMMON CORRELATIONS
  res["correlation"] = res["correlation"].fill_diagonal_(0)
    
  return res

res = preprocess()

import numba
from numba import prange,njit

@njit(cache=True, parallel=True)
def indexFunc4(x):
    max_indices = np.zeros((x.shape[0],),dtype=np.float32)
    for i in prange(x.shape[0]):
            max_indices[i] = np.argmax(x[i]) 
    return max_indices

one_mask = torch.ones(size=(200,)).to(device)

alpha = 1
beta = 0

def score(x_tensor = x_tensor,y_tensor = y_tensor,mask = one_mask,num_class = 16,alpha = alpha,beta = beta):
  # SAM CLASSIFICATION
  x_tensor_masked = torch.mul(x_tensor,mask) # MUL1
  mask_mean = mask.broadcast_to((num_class,num_bands))
  mean_stack_masked = torch.mul(res["mean_stack"],mask_mean) # MUL2
  mean_stack_masked = mean_stack_masked.t()

  dots = torch.mm(x_tensor_masked,mean_stack_masked) # MM1

  norm_x = torch.sqrt(torch.sum(x_tensor_masked.pow_(2),dim = 1)).view(-1,1) # SUM1(10000*2000)

  norm_mean = torch.sqrt(torch.sum(mean_stack_masked.pow_(2),dim = 0)).view(1,-1) # SUM2(16*200)

  norm_product = torch.mm(norm_x,norm_mean) # MM2

  cosines = torch.div(dots,norm_product) # DIV1

  result = torch.argmax(cosines,dim=1) if torch.cuda.is_available() else torch.from_numpy(indexFunc4(cosines.numpy()))
  # ACCURACY MEASUREMENT
  accuracy = torch.sum(result == y_tensor,dtype = torch.int16) / x_tensor.shape[0] # SUM3(10000)
  # DISTANCE BETWEEN MEANS CALCULATION
  mask_diffs = mask.broadcast_to((num_class,num_class,num_bands)) 
  masked_mean_diffs = torch.mul(res["mean_diffs"],mask_diffs) # MUL3
  
  masked_mean_distances = torch._C._VariableFunctions.frobenius_norm(masked_mean_diffs,2,False)
  mean_distance = torch.sum(masked_mean_distances) / (num_class * (num_class - 1)) #SUM4(256)
  # BAND CORRELATION CALCULATION
  mask_2d = torch.mm(mask.view(-1,1),mask.view(1,-1)) # MM3
  no_bands = torch.sum(mask,dtype=torch.int32) # SUM5(200)

  masked_correlation = torch.mul(res["correlation"],mask_2d) # MUL4
  band_corr = torch.sum(masked_correlation) / (no_bands * (no_bands - 1)) #
  #print(accuracy,mean_distance,band_corr)
  return alpha*accuracy + beta*mean_distance + (1-alpha-beta)*band_corr

score()

print(x_tensor.shape)

def test_ang(data,members):
  m = np.array(members, np.float64)
  m /= np.sqrt(np.einsum('ij,ij->i', m, m))[:, np.newaxis]

  norms = np.linalg.norm(data,axis=1)
  dots = np.einsum('ik,mk->im', data, m)
  dots = np.clip(dots / norms[:, np.newaxis], -1, 1)
  return np.arccos(dots),dots

import spectral
#classes = spectral.create_training_classes(x_tensor.numpy(), y_tensor.numpy(), True)
#means = np.zeros((len(classes), flattened_image.shape[1]), np.float64)
#for k,v in res["mean"].items():
#  means[k] = v 
#angles,dots = test_ang(x_tensor.numpy(), means)
clmap = np.argmin(angles, 1)
#print(sum(clmap == y_tensor.numpy()))
#print(sum(np.argmin(np.arccos(test_cosines.numpy()),axis=1) == y_tensor.numpy()))
#print(sum(test_res == y_tensor))
#print(np.where(test_res.numpy() != clmap))
#print(sum(abs(test_cosines.numpy()-dots)>0.001))
print(dots)
print(x_tensor)
print(torch.sum(test_res == y_tensor)/10249)

import numpy as np
import random
"""
Way to optimize - Choose Linear Search run on range of vals for each variable and choose its optimum and use as value for next
Optimal population size = 40
Compared various populations to maximize 0.[8,9] * score - 0.[2,1] * time
Optimal number of generations = 200
Compared various values to maximize 0.[9,95] * score - 0.[1,05] * time
TODO: Optimize alpha,beta,pcross,pmut,pswap all in [0,1] except alpha + beta <= 1
"""
compressedbands=70
totalbands=200
totalsamples=40
pcross = 0.1
pmut = 0.2
pselect = 0.7
pswap = 0.3

class GSA:
    def __init__(self):
        self.population = [torch.zeros((totalbands,),device=device) for _ in range(totalsamples)]

        for j in range(totalsamples):
            randomiser = np.random.choice(totalbands,size=compressedbands,replace=False)
            for i in range(compressedbands):
                self.population[j][randomiser[i]]=1

    def selection(self):
      newpop = [self.population[i] for i in range(totalsamples)]
      self.population = newpop

    def crossover(self):
      """
        BASELINE BENCHMARK - 1 ms for a totsamples = 10
      """
      orig = np.arange(totalsamples)
      orig = np.random.choice(orig,size=int(pcross*totalsamples))
      if len(orig) == 1:
        pass
      else:
        w = len(orig)
        if (w % 2) == 1:
          w -=1
        for i in range(0,w,2):
          self.population += self.cross(self.population[orig[i]],self.population[orig[i+1]])
    
    def print(self):
      print(self.population)
    
    def size(self):
      print(len(self.population))
    
    @staticmethod
    def cross(x,y):
      x_c = x.clone().detach().cpu()
      y_c = y.clone().detach().cpu()
      pos10 = np.where((x_c == 1) & (y_c == 0))[0]
      pos01 = np.where((x_c == 0) & (y_c == 1))[0]
      swap10 = np.random.choice(pos10,size=int(pswap*len(pos10)),replace=False)
      swap01 = np.random.choice(pos01,size=int(pswap*len(pos10)),replace=False)
      for i in swap10:
        x_c[i] = 0
        y_c[i] = 1
      for i in swap01:
        x_c[i] = 1
        y_c[i] = 0
      return [x_c.to(device),y_c.to(device)]

    def mutate(self):
      """
       BASELINE BENCHMARK - 0.3 ms for totalsamples = 10
      """
      l = len(self.population)
      for i in range(l):
        toss = np.random.binomial(1,pmut)
        if toss:
          modpop = self.population[i].clone().detach().cpu()
          pos1 = np.where(modpop == 1)[0]
          oneto0 = np.random.choice(pos1,size=1)
          pos0 = np.where(modpop == 0)[0]
          zeroto1 = np.random.choice(pos0,size=1)
          modpop[oneto0] = 0
          modpop[zeroto1] = 1
          self.population += [modpop.to(device)]
        
    def fit(self):
      """
        BASELINE BENCHMARK - 6 ms per individual
      """
      self.scores = { p : score(mask = p) for p in self.population }
      self.population = sorted(self.population,key=lambda x:self.scores[x],reverse=True)
    
    def generate(self):
      """
        BASELINE BENCHMARK - 7.8 s for 100 generations with totsamples = 10
                           - 0.62 s for 100 generations with totsamples = 10 on CUDA backend
                           - 18 s for 100 generations with totsamples = 20
                           - 1.4 s for 100 generations with totsamples = 20 on CUDA backend
      """
      self.crossover()
      self.mutate()
      self.fit()
      self.selection()
    
    @staticmethod
    def benchmark():
      pop_sizes = [10*i for i in range(1,11)]
      gen_nums = [100*i for i in range(1,11)]
      time_benchmark_pop = []
      time_benchmark_gen = []
      score_benchmark_pop = []
      score_benchmark_gen = [] 
      totalsamples = 10
      if torch.cuda.is_available():
        for gen_num in gen_nums:
          print(f"RUNNING FOR number of generations = {gen_num}")
          test_GSA = GSA()
          start = torch.cuda.Event(enable_timing=True)
          end = torch.cuda.Event(enable_timing=True)
          start.record()
          for _ in range(gen_num):
            test_GSA.generate()
          end.record()
          torch.cuda.synchronize()
          time_benchmark_gen.append(start.elapsed_time(end))
          score_benchmark_gen.append(score(mask=test_GSA.population[0]))
        for pop_size in pop_sizes:
          print(f"RUNNING FOR population = {pop_size}")
          totalsamples = pop_size
          test_GSA = GSA()
          start = torch.cuda.Event(enable_timing=True)
          end = torch.cuda.Event(enable_timing=True)
          start.record()
          for _ in range(100):
            test_GSA.generate()
          end.record()
          torch.cuda.synchronize()
          time_benchmark_pop.append(start.elapsed_time(end))
          score_benchmark_pop.append(score(mask=test_GSA.population[0]))
      else:
        for gen_num in gen_nums:
          test_GSA = GSA()
          start = time.time()
          for _ in range(gen_num):
            test_GSA.generate()
          end = time.time()
          time_benchmark_gen.append((end-start)*1000)
          score_benchmark_gen.append(score(mask=test_GSA.population[0]))
        for pop_size in pop_sizes:
          totalsamples = pop_size
          test_GSA = GSA()
          start = time.time()
          for _ in range(100):
            test_GSA.generate()
          end = time.time
          time_benchmark_pop.append((end-start)*1000)
          score_benchmark_pop.append(score(mask=test_GSA.population[0]))
      
      benchmarks = {
        "time_benchmark_pop" : np.array(time_benchmark_pop),
        "time_benchmark_gen" : np.array(time_benchmark_gen),
        "score_benchmark_pop" : np.array(score_benchmark_pop),
        "score_benchmark_gen" : np.array(score_benchmark_gen)
      }
      
      for name,val in benchmarks.items():
        with open(name+".npy","wb") as f:
          print(f"SAVING {name}")
          np.save(f, val)
      
      open("time-population.png", 'w').close()
      open("score-population.png", 'w').close()
      open("time-generations.png", 'w').close()
      open("score-generations.png", 'w').close()

      fig = plt.figure(1, figsize=(6, 6))
      plt.plot(pop_sizes,time_benchmark_pop,marker = "o",color = "blue")
      plt.savefig("time-population.png")
      plt.close(fig)

      fig = plt.figure(2, figsize=(6, 6))
      plt.plot(pop_sizes,score_benchmark_pop,marker = "o",color = "blue")
      plt.savefig("score-population.png")
      plt.close(fig)

      fig = plt.figure(3, figsize=(6, 6))
      plt.plot(gen_nums,time_benchmark_gen,marker = "o",color = "blue")
      plt.savefig("time-generations.png")
      plt.close(fig)

      fig = plt.figure(4, figsize=(6, 6))
      plt.plot(gen_nums,score_benchmark_gen,marker = "o",color = "blue")
      plt.savefig("score-generations.png")
      plt.close(fig)

      return benchmarks

    @staticmethod
    def test(func="mutate"):
      import time
      test_GSA = GSA()
      if func == "mutate":
        counter = 0
        for _ in range(1000):
          test_GSA.selection()
          s1 = time.time()
          test_GSA.mutate()
          e1 = time.time()
          counter += (e1-s1)
        print(counter)
      elif func == "fit":
        counter = 0
        for _ in range(100):
          test_GSA = GSA()
          s1 = time.time()
          test_GSA.fit()
          e1 = time.time()
          counter += (e1-s1)
        print(counter*10)
      elif func == "init":
        counter = 0
        for _ in range(1000):
          s1 = time.time()
          test_GSA = GSA()
          e1 = time.time()
          counter += (e1-s1)
        print(counter)
      elif func == "cross":
        counter = 0
        for _ in range(100):
          test_GSA.selection()
          s1 = time.time()
          test_GSA.crossover()
          e1 = time.time()
          counter += (e1-s1)
        print(counter*10)
      elif "generation":
        counter = 0
        if torch.cuda.is_available():
          start = torch.cuda.Event(enable_timing=True)
          end = torch.cuda.Event(enable_timing=True)
          start.record()
          #with torch.autograd.profiler.profile(use_cuda=True) as prof:
          for _ in range(100):
            test_GSA.generate()
          end.record()
          torch.cuda.synchronize()
          print(start.elapsed_time(end))
          #print(prof.key_averages().table(sort_by="cuda_time_total"))
        else:
          for _ in range(100):
            s1 = time.time()
            test_GSA.generate()
            e1 = time.time()
            counter += (e1-s1)
          print(counter*10)
      else:
        counter = 0
        for _ in range(1000):
          test_GSA.mutate()
          s1 = time.time()
          test_GSA.selection()
          e1 = time.time()
          counter += (e1-s1)
        print(counter)
  
if __name__ == '__main__':
    weight = GSA()

import numpy as np
import random

compressedbands=70
totalbands=200
totalsamples=10
pcross = 0
pmut = 0.2
pselect = 0.7
protten = 0.01
max_sel = 3
class GSA:
    def __init__(self):
        self.array = np.zeros((totalsamples,totalbands))
        self.fitness = np.zeros((totalsamples,1))
        self.rating = list(zip(self.array,self.fitness))
        #for i in range(totalsamples):
            #self.fitness[i] = fitness(self.array[i,:])
        #   self.fitness[i] = 10-i
        for j in range(totalsamples):
            randomiser = np.random.choice(totalbands,size=compressedbands,replace=False)
            for i in range(compressedbands):
                self.array[j,randomiser[i]]=1
    def transition(self):
        randomizer = np.random.choice(totalsamples,size=int(totalsamples*(pcross+pmut)),replace=False)
        print(randomizer)
        for i in range(0,int(totalsamples*pcross),2):
            r1 = random.randint(1,max_sel)
            for i in range(r1):
                while(True):
                    r = random.randint(0,totalbands-1)
                    if((self.array[randomizer[i],r] != self.array[randomizer[i+1],r]) and self.array[randomizer[i],r] == 1):
                        self.array[randomizer[i],r] = 0
                        self.array[randomizer[i+1],r] = 1
                        break
                while(True):
                    r = random.randint(0,totalbands-1)
                    if((self.array[randomizer[i],r] != self.array[randomizer[i+1],r]) and self.array[randomizer[i+1],r] == 1):
                        self.array[randomizer[i],r] = 1
                        self.array[randomizer[i+1],r] = 0
                        break
        for i in range(int(totalsamples*pmut)):
                while(True):
                    r = random.randint(0,totalbands-1)
                    if(self.array[randomizer[i+int(totalsamples*pcross)],r] == 1):
                        self.array[randomizer[i+int(totalsamples*pcross)],r] = 0
                        break
                while(True):
                    r = random.randint(0,totalbands-1)
                    if(self.array[randomizer[i+int(totalsamples*pcross)],r] == 0):
                        self.array[randomizer[i+int(totalsamples*pcross)],r] = 1
                        break
    def elim(self):
        #for i in range(totalsamples):
        #   #self.fitness[i] = fitness(self.array[i,:])
        self.rating=list(map(lambda x:(x[0],score(mask=torch.from_numpy(x[0]).to(device))),self.rating))
        self.rating.sort(key = lambda x: x[1],reverse=True)
        pos = int(totalsamples*pselect)
        for i in range(int(totalsamples*pselect),totalsamples):
            val = np.random.binomial(1,protten)
            if val==0:
                self.rating.pop(pos)
            else:
                pos=pos+1

    def print(self):
        print(self.rating)

  
if __name__ == '__main__':
    weight = GSA()
    print(len(weight.rating))
    weight.transition()
    #weight.print()
    weight.elim()
    #weight.print()

# Tuning Hyperparameters
# Algorithm params
scorer = None
weight_to_score = 0.8
oscillate = 0.5
possible_weights = [weight_to_score-oscillate,weight_to_score,weight_to_score+oscillate]

#################################################################################################################################
########## Algoritmic score and possible search space generators ################################################################
#################################################################################################################################

def tune_population_size():
    pop_sizes = [10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200]
    mapper = lambda x:pop_sizes[x]
    vector_mapper = np.vectorize(mapper)
    mean_benchmark_pop = []
    max_benchmark_pop = []
    for pop_size in pop_sizes:
      print(f"RUNNING FOR population = {pop_size}")
      totalsamples = pop_size
      test_GSA = GSA()
      start = torch.cuda.Event(enable_timing=True)
      end = torch.cuda.Event(enable_timing=True)
      start.record()
      for _ in range(100):
        test_GSA.generate()
      end.record()
      torch.cuda.synchronize()
      time_used = start.elapsed_time(end))/20000
      scores = [scorer(test_GSA.population[i]) for i in range(10)]
      mean_score = sum(scores)//10
      max_score = max(scores)
      max_data = [w*max_score-(1-w)*time_used for w in possible_weights]
      mean_data = [w*mean_score-(1-w)*time_used for w in possible_weights]
      max_benchmark_pop.append(max_data)
      mean_benchmark_pop.append(mean_data)
    file_max = open("max_benchmark.txt","wb")
    file_mean = open("mean_benchmark.txt","wb")
    import pickle
    pickle.dump(max_benchmark_pop,file_max)
    pickle.dump(mean_benchmark_pop,file_mean)
    file_max.close()
    file_mean.close()
    mean_array = np.array(mean_benchmark_pop)
    max_array = np.array(max_benchmark_pop)
    max_opt = np.argmax(max_array,axis=0)
    max_opt = vector_mapper(max_opt)
    mean_opt = np.argmax(mean_array,axis=0)
    mean_opt = vector_mapper(mean_opt)
    print("-"*20)
    print("MAXIMUM SCORE RESULTS:")
    print(max_opt)
    print("-"*20)
    print("MEAN SCORE RESULTS:")
    print(mean_opt)
    print("-"*20)

def tune_num_generations():
  num_gens = [50*i for i in range(1,21)]
  mapper = lambda x:num_gens[x]
  vector_mapper = np.vectorize(mapper)
  mean_benchmark_pop = []
  max_benchmark_pop = []
  for num_gen in num_gens:
    print(f"RUNNING FOR generations = {num_gen}")
    test_GSA = GSA()
    start = torch.cuda.Event(enable_timing=True)
    end = torch.cuda.Event(enable_timing=True)
    start.record()
    for _ in range(num_gen):
      test_GSA.generate()
    end.record()
    torch.cuda.synchronize()
    time_used = start.elapsed_time(end))/20000
    scores = [scorer(test_GSA.population[i]) for i in range(10)]
    mean_score = sum(scores)//10
    max_score = max(scores)
    max_data = [w*max_score-(1-w)*time_used for w in possible_weights]
    mean_data = [w*mean_score-(1-w)*time_used for w in possible_weights]
    max_benchmark_pop.append(max_data)
    mean_benchmark_pop.append(mean_data)
  file_max = open("max_benchmark_gens.txt","wb")
  file_mean = open("mean_benchmark_gens.txt","wb")
  import pickle
  pickle.dump(max_benchmark_pop,file_max)
  pickle.dump(mean_benchmark_pop,file_mean)
  file_max.close()
  file_mean.close()
  mean_array = np.array(mean_benchmark_pop)
  max_array = np.array(max_benchmark_pop)
  max_opt = np.argmax(max_array,axis=0)
  max_opt = vector_mapper(max_opt)
  mean_opt = np.argmax(mean_array,axis=0)
  mean_opt = vector_mapper(mean_opt)
  print("-"*20)
  print("MAXIMUM SCORE RESULTS:")
  print(max_opt)
  print("-"*20)
  print("MEAN SCORE RESULTS:")
  print(mean_opt)
  print("-"*20)

#################################################################################################################################
########## Algorithm runs and user based optimal selection ######################################################################
#################################################################################################################################

tune_population_size()
totalsamples = int(input("CHOOSE RESULT FROM DATA:"))
tune_num_generations()
generations = int(input("CHOOSE RESULT FROM DATA:"))
print("-"*20)
print("PRINTING FINAL PARAMETER SET:")
print("-"*20)
print(f"POPULATION SIZE = {totalsamples}")
print(f"NUMBER OF GENERATIONS = {generations}")

pop_sizes = [10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220]
time_benchmark_pop = []
score_benchmark_pop = []
for pop_size in pop_sizes:
  print(f"RUNNING FOR population = {pop_size}")
  totalsamples = pop_size
  test_GSA = GSA()
  start = torch.cuda.Event(enable_timing=True)
  end = torch.cuda.Event(enable_timing=True)
  start.record()
  for _ in range(100):
    test_GSA.generate()
  end.record()
  torch.cuda.synchronize()
  time_benchmark_pop.append(start.elapsed_time(end))
  score_benchmark_pop.append(score(mask=test_GSA.population[0]))

plt.plot(pop_sizes,time_benchmark_pop)
plt.plot(pop_sizes,score_benchmark_pop)

plt.figure(1,figsize=(10,10))
plt.plot(pop_sizes,time_benchmark_pop)

plt.figure(2,figsize=(10,10))
plt.plot(pop_sizes,score_benchmark_pop)

norm_time_benchmark_pop = [t/max(time_benchmark_pop) for t in time_benchmark_pop]
norm_score_benchmark_pop = [t/max(score_benchmark_pop) for t in score_benchmark_pop]
compare_metric = zip(norm_score_benchmark_pop,norm_time_benchmark_pop)
compare_metric = [float(0.95*x-0.05*y) for x,y in compare_metric]
print(sorted(list(zip(pop_sizes,compare_metric)),key = lambda x:x[1],reverse=True))
plt.figure(2,figsize=(10,10))
plt.plot(pop_sizes,compare_metric)

num_gens = [50*i for i in range(1,21)]
time_benchmark_gen = []
score_benchmark_gen = []
for num_gen in num_gens:
  print(f"RUNNING FOR generations = {num_gen}")
  totalsamples = 40
  test_GSA = GSA()
  start = torch.cuda.Event(enable_timing=True)
  end = torch.cuda.Event(enable_timing=True)
  start.record()
  for _ in range(num_gen):
    test_GSA.generate()
  end.record()
  torch.cuda.synchronize()
  time_benchmark_gen.append(start.elapsed_time(end))
  score_benchmark_gen.append(score(mask=test_GSA.population[0]))

plt.figure(3,figsize=(10,10))
plt.plot(num_gens,time_benchmark_gen)

plt.figure(4,figsize=(10,10))
plt.plot(num_gens,score_benchmark_gen)

norm_time_benchmark_gen = [t/max(time_benchmark_gen) for t in time_benchmark_gen]
norm_score_benchmark_gen = [t/max(score_benchmark_gen) for t in score_benchmark_gen]
compare_metric_gen = zip(norm_score_benchmark_gen,norm_time_benchmark_gen)
compare_metric_gen = [float(0.95*x-0.05*y) for x,y in compare_metric_gen]
print(sorted(list(zip(num_gens,compare_metric_gen)),key = lambda x:x[1],reverse=True))
plt.figure(2,figsize=(10,10))
plt.plot(num_gens,compare_metric_gen)

alpha_set = [0.1*i for i in range(11)]
alpha_beta_results = []
for alpha_val in alpha_set:
  max_beta = int((1-alpha_val)/0.1)
  beta_set = [0.1*i for i in range(max_beta)]
  for beta_val in beta_set:
    print(f"ALPHA = {alpha_val} , BETA = {beta_val}")
    alpha = alpha_val
    beta = beta_val
    totalsamples=40
    test_GSA = GSA()
    for _ in range(200):
      test_GSA.generate()
    alpha_beta_results.append({"alp":alpha_val,"bet":beta_val,"GSA":test_GSA,"max_score":score(mask=test_GSA.population[0])})

fileloader = open("alphabeta","wb")
pickle.dump(alpha_beta_results,fileloader)
fileloader.close()

import pickle
fileloader = open("alphabeta","rb")
alpha_beta_results = pickle.load(fileloader)
fileloader.close()

for x in alpha_beta_results:
  model = x["GSA"]
  pop = model.population
  scores_pop = np.array(list(map(lambda x:float(score(mask=x)),pop)))
  agg_mean = np.mean(scores_pop)
  agg_std = np.std(scores_pop)
  x["mean"] = agg_mean
  x["std"] = agg_std
  x["min_score"] = min(scores_pop)
  x["max_score"] = max(scores_pop)

points_x = []
points_y = []
points_mean = []
points_std = []
points_min = []
points_max = []
for x in alpha_beta_results:
  points_x.append(x["alp"])
  points_y.append(x["bet"])
  points_mean.append(x["mean"])
  points_std.append(x["std"])
  points_max.append(x["max_score"])
  points_min.append(x["min_score"])
points_x = np.array(points_x)
points_y = np.array(points_y)
points_mean = np.array(points_mean)
points_std = np.array(points_std)
points_min = np.array(points_min)
points_max = np.array(points_max)

alpha_beta_sorted_max = [(x["alp"],x["bet"]) for x in sorted(alpha_beta_results,key = lambda x:x["max_score"],reverse=True)]
alpha_beta_sorted_min = [(x["alp"],x["bet"]) for x in sorted(alpha_beta_results,key = lambda x:x["min_score"],reverse=True)]
alpha_beta_sorted_mean = [(x["alp"],x["bet"]) for x in sorted(alpha_beta_results,key = lambda x:x["mean"],reverse=True)]

sorted(alpha_beta_results,key = lambda x:x["max_score"],reverse=True)

from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure()
fig.set_size_inches(6, 6)
ax = Axes3D(fig)
ax.scatter(points_x, points_y, points_mean,label="mean")
ax.scatter(points_x, points_y, points_max,label="max")
ax.scatter(points_x, points_y, points_min,label="min")
plt.xlabel('alpha')
plt.ylabel('beta')
ax.legend(loc="best")
plt.show()